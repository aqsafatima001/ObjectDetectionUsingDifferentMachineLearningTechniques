# -*- coding: utf-8 -*-
"""MLP_ObjectDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kS5iD2nysC-8Nrrc59Pg4NYcrxAuNDcl

# **IMPORT Libraries**
"""

import tensorflow as tf
from tensorflow.keras import datasets
import numpy as np
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import accuracy_score

"""# **LOAD CIFAR10 dataset**"""

# Load CIFAR-10 dataset
(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()

"""# **Flatten the images**"""

# Flatten the images for logistic regression
X_train_flat = X_train.reshape((X_train.shape[0], -1))
X_test_flat = X_test.reshape((X_test.shape[0], -1))

"""# **Normalize pixel values to be in the range [0, 1]**"""

# Normalize pixel values to be in the range [0, 1]
X_train_flat = X_train_flat / 255.0
X_test_flat = X_test_flat / 255.0

"""# **Initialize the StandardScaler**"""

# Initialize the StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_flat)
X_test_scaled = scaler.transform(X_test_flat)

"""# **Define the parameter grid for randomized search**"""

# Define the parameter grid for randomized search
param_dist = {
    'hidden_layer_sizes': [256],
    'activation': ['relu'],
    'learning_rate_init': [0.0001],
    'alpha': [3.76],
    'batch_size': [64],
    'max_iter': [10],
    'solver': ['sgd'],
}

"""# **MLPClassifier**"""

# Initialize the MLPClassifier
mlp = MLPClassifier(random_state=42)

# Initialize the RandomizedSearchCV
random_search = RandomizedSearchCV(
    mlp,
    param_distributions=param_dist,
    n_iter=10,  # Number of parameter settings that are sampled
    scoring='accuracy',  # You can choose a different scoring metric
    cv=5,  # Number of cross-validation folds
    n_jobs=-1,  # Use all available CPU cores
    random_state=42
)

# Fit the RandomizedSearchCV to the data
random_search.fit(X_train_scaled, y_train.ravel())

# Get the best parameters and the best model
best_params = random_search.best_params_
best_mlp = random_search.best_estimator_

# Make predictions on the test set
y_pred_mlp = best_mlp.predict(X_test_scaled)

# Calculate accuracy
accuracy_mlp = accuracy_score(y_test, y_pred_mlp)
print(f"MLP Accuracy: {accuracy_mlp}")

# Print the best hyperparameters
print("Best Hyperparameters:")
print(best_params)